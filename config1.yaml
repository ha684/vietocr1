aug:
  image_aug: true
  masked_language_model: true
backbone: vision
cnn:
  encoder_depth: 12
  encoder_embed_dim: 768
  encoder_global_attn_indexes:
  - 2
  - 5
  - 8
  - 11
  encoder_num_heads: 12
  hidden: 256
  vit_patch_size: 16
dataloader:
  num_workers: 0
  pin_memory: true
dataset:
  data_root: D:\Workspace\python_code\ImageGenerations\images_out
  image_height: 32
  image_max_width: 512
  image_min_width: 32
  name: ha
  train_annotation: label_train.txt
  valid_annotation: label_test.txt
device: cuda:0
optimizer:
  max_lr: 0.01
  pct_start: 0.05
predictor:
  beamsearch: false
quiet: false
seq_modeling: seq2seq
trainer:
  batch_size: 1
  checkpoint: ./checkpoint/transformers_checkpoint.pth
  epochs: 10
  export: ./weights/transformers.pth
  iters: 100000
  log: ./train.log
  metrics: 10000
  patience: 5
  print_every: 1
  valid_every: 1000
transformer:
  decoder_embedded: 512
  decoder_hidden: 512
  dropout: 0.0
  encoder_hidden: 512
  img_channel: 1024
vocab: aAàÀảẢãÃáÁạẠăĂằẰẳẲẵẴắẮặẶâÂầẦẩẨẫẪấẤậẬbBcCdDđĐeEèÈẻẺẽẼéÉẹẸêÊềỀểỂễỄếẾệỆfFgGhHiIìÌỉỈĩĨíÍịỊjJkKlLmMnNoOòÒỏỎõÕóÓọỌôÔồỒổỔỗỖốỐộỘơƠờỜởỞỡỠớỚợỢpPqQrRsStTuUùÙủỦũŨúÚụỤưƯừỪửỬữỮứỨựỰvVwWxXyYỳỲỷỶỹỸýÝỵỴzZ0123456789!"#$%&()*+,-./:;<=>?@[\]^_`{|}~’
  '
